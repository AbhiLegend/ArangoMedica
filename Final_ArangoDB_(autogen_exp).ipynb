{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Installing The Required Dependencies**"
      ],
      "metadata": {
        "id": "vr4N1wTNPBvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nx-arangodb\n",
        "!pip install langgraph-prebuilt\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com"
      ],
      "metadata": {
        "id": "oTRDtFXdBfR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph"
      ],
      "metadata": {
        "id": "rSg0l4AwByQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen-agentchat~=0.2"
      ],
      "metadata": {
        "id": "-wqwlmYcPNdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen"
      ],
      "metadata": {
        "id": "wodEBiQvPbYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting Up the env variables which also enables CUGRAPH as NETWORKX backend**"
      ],
      "metadata": {
        "id": "9VnD2CYnPqOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env NX_CUGRAPH_AUTOCONFIG=True"
      ],
      "metadata": {
        "id": "HME_xDFoBvPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LC_ALL\"] = \"C.UTF-8\"\n",
        "os.environ[\"LANG\"] = \"C.UTF-8\""
      ],
      "metadata": {
        "id": "aM3d3yiv19M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the Required Libraries**"
      ],
      "metadata": {
        "id": "CS_rHknKPybe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "id": "rrAOgWrzB0nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting the ArangoDB database**"
      ],
      "metadata": {
        "id": "Q8W_6DGGP6Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = ArangoClient(hosts=\"https://0635a9c68bd8.arangodb.cloud:8529\").db(username=\"root\", password=\"xoIqUBS650nNHQQInV1T\", verify=True)\n",
        "\n",
        "print(db)"
      ],
      "metadata": {
        "id": "kPyJwj3a1n6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accessing the Graph from the database and also applying some AQL to validate that the persistance was perfect**"
      ],
      "metadata": {
        "id": "gTzFV06MQBPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G_adb = nxadb.Graph(name=\"medical\", db=db)\n",
        "\n",
        "print(G_adb)"
      ],
      "metadata": {
        "id": "nh0qE6j63WTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print one node with attributes\n",
        "print(\"Sample Node in G_adb:\")\n",
        "print(next(iter(G_adb.nodes(data=True))))\n",
        "\n",
        "# Print one edge with attributes\n",
        "print(\"\\nSample Edge in G_adb:\")\n",
        "print(next(iter(G_adb.edges(data=True))))\n"
      ],
      "metadata": {
        "id": "1mihXdqB3bWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_count = db.aql.execute(\"RETURN LENGTH(medical_node)\")\n",
        "print(f\"Total Nodes: {list(node_count)[0]}\")"
      ],
      "metadata": {
        "id": "xZlCJa0zQJny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_count = db.aql.execute(\"RETURN LENGTH(medical_node_to_medical_node)\")\n",
        "print(f\"Total Edges: {list(edge_count)[0]}\")"
      ],
      "metadata": {
        "id": "xI72wFkXQRE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up the ArangoGraph wrapper and also initialising the LLM**"
      ],
      "metadata": {
        "id": "p3izb8qoQRfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arango_graph = ArangoGraph(db)"
      ],
      "metadata": {
        "id": "Zrj1CsLYTxyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get('OPEN_API_KEY')\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "llm.invoke(\"hello!\")"
      ],
      "metadata": {
        "id": "0PwtPI85Ty4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"PUT IN YOUR OPENAI KEY HERE\"\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "llm.invoke(\"hello!\")"
      ],
      "metadata": {
        "id": "Z2L8e121SYyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the Required Tools**"
      ],
      "metadata": {
        "id": "DBZnQ7vxQjNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text to Aql to Text"
      ],
      "metadata": {
        "id": "DJo42FrNQnkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ArangoGraphQAChain\n",
        "\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"Translates a Natural Language Query into AQL while ensuring correct edge types.\"\"\"\n",
        "\n",
        "    # Define allowed edge types\n",
        "    edge_types = [\n",
        "        \"DISEASE_HAS_TREATMENT\",\n",
        "        \"PATIENT_DIAGNOSED_WITH\",\n",
        "        \"DISEASE_HAS_DRUG\",\n",
        "        \"SYMPTOM_INDICATES_DISEASE\",\n",
        "        \"DISEASE_HAS_GENE\",\n",
        "        \"DRUG_INTERACTS_WITH\",\n",
        "        \"PATIENT_HAS_SYMPTOM\"\n",
        "    ]\n",
        "\n",
        "    # Construct LLM instructions\n",
        "    instruction_prompt = (\n",
        "        f\"You are an expert in graph databases and AQL. Your task is to analyze the given \"\n",
        "        f\"natural language query and determine whether an edge type from the following list \"\n",
        "        f\"is required: {', '.join(edge_types)}.\\n\\n\"\n",
        "        \"If an edge type is required, **strictly select one** from this list and use it in the AQL query.\\n\"\n",
        "        \"**Do NOT create or assume any other edge types beyond this list.**\\n\\n\"\n",
        "        \"If no edge type is required, generate a standard AQL query without using any edge.\\n\\n\"\n",
        "        f\"Here is the user query:\\n\\n{query}\"\n",
        "    )\n",
        "\n",
        "    # Configure LLM\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    # Set up ArangoGraphQAChain\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=True,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    # Generate and execute AQL query\n",
        "    result = chain.invoke(instruction_prompt)\n",
        "\n",
        "    return str(result[\"result\"])\n"
      ],
      "metadata": {
        "id": "60-NZFrmtU34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text to NetworkX Algorithm to Text"
      ],
      "metadata": {
        "id": "scC8ZRlgQtw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import networkx as nx\n",
        "from langchain_openai import ChatOpenAI\n",
        "from collections import Counter\n",
        "\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"Executes a NetworkX computation on the Medical ArangoDB Graph.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    # Generate Python NetworkX Code using LLM\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    You are an expert Python programmer specializing in **NetworkX and graph traversal**.\n",
        "\n",
        "    ### **Your Task:**\n",
        "    - Generate **valid Python NetworkX code** to process queries related to a **Medical Knowledge Graph {G_adb}**.\n",
        "    - `G_adb` is **already defined and populated**â€” **DO NOT** reinitialize it (e.g., `G_adb = nx.Graph()`).\n",
        "    - The graph consists of:\n",
        "      - **Nodes** with `id` and `type` attributes. Types include:\n",
        "        - **'Patient', 'Symptom', 'Gene', 'Drug', 'Treatment', 'Disease'**\n",
        "      - **Edges** with a `type` attribute defining relationships.\n",
        "\n",
        "    ### **Instructions for Code Generation:**\n",
        "    1. **Understand the query** and determine the best approach.\n",
        "    2. **If the query is node-specific** (e.g., diseases, symptoms, patients, drugs, treatments), process the relevant nodes and edges intelligently.\n",
        "    3. **If the query is general** (e.g., graph structure, connectivity, centrality, shortest paths), judge all possible NetworkX methods and select the most appropriate one.\n",
        "    4. **Ensure safe execution** by wrapping the logic inside `try-except`.\n",
        "    5. **Assign the result to `FINAL_RESULT`**.\n",
        "    6. **Include debug prints** for intermediate steps.\n",
        "\n",
        "    ### **Query Handling:**\n",
        "    âœ… **Node-Specific Queries:**\n",
        "      - Find symptoms of a disease, drug effectiveness, patient symptoms, etc.\n",
        "      - Use relationships like `\"SYMPTOM_INDICATES_DISEASE\"`, `\"PATIENT_HAS_SYMPTOM\"`, `\"DISEASE_HAS_GENE\"`, `\"DRUG_INTERACTS_WITH\"`, `\"DISEASE_HAS_TREATMENT\"`, `\"PATIENT_DIAGNOSED_WITH\"`, `\"DISEASE_HAS_DRUG\"`.\n",
        "    âœ… **Graph Algorithms (General Queries):**\n",
        "      - For graph-wide questions, analyze all possible NetworkX functions (connectivity, shortest paths, centrality, clustering, etc.).\n",
        "      - Do **not** explicitly assume a functionâ€”first evaluate all relevant possibilities.\n",
        "    âœ… **Ensure Execution Completeness:**\n",
        "      - If multiple approaches are valid, return the most informative one.\n",
        "\n",
        "    ### **Response Rules:**\n",
        "    âœ… Contain **ONLY valid Python code**â€”no explanations or markdown.\n",
        "    âœ… **Use NetworkX** functions appropriately.\n",
        "    âœ… **Handle errors safely** using `try-except`.\n",
        "    âœ… **Ensure FINAL_RESULT contains meaningful output (e.g., symptom names instead of node IDs).**\n",
        "\n",
        "    ---\n",
        "\n",
        "    **Query:** \"{query}\"\n",
        "    **Your response should contain ONLY Python code following these rules.**  # Use the refined prompt here\n",
        "            \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^\\`\\`\\`python\\n|\\`\\`\\`$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-' * 10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-' * 10)\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "\n",
        "    global_vars = {\n",
        "        \"G_adb\": G_adb,\n",
        "        \"nx\": nx,\n",
        "        \"Counter\": Counter\n",
        "    }\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        FINAL_RESULT = local_vars.get(\"FINAL_RESULT\", \"Execution failed\")\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        FINAL_RESULT = f\"EXEC ERROR: {e}\"\n",
        "\n",
        "    print('-' * 10)\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-' * 10)\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "    The **generated Python code** executed and returned: {FINAL_RESULT}.\n",
        "    Based on this, generate a **concise** response.\n",
        "\n",
        "    Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n",
        "\n"
      ],
      "metadata": {
        "id": "wmKjuzQO7tWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Query"
      ],
      "metadata": {
        "id": "O1IfEIqfQ7aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ArangoGraphQAChain\n",
        "import logging\n",
        "import ast\n",
        "\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "@tool\n",
        "def execute_hybrid_query(query):\n",
        "    \"\"\"Determines execution plan and processes query using AQL and NetworkX accordingly.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    # Step 1: Determine query execution strategy\n",
        "    prompt = f\"\"\"\n",
        "    You are an AI assistant. Given the query below, extract the **AQL query** and **NetworkX algorithm** separately.\n",
        "\n",
        "    ### **Rules:**\n",
        "    - If the query requires retrieving data from ArangoDB, generate a valid **AQL query** based on the dataset structure.\n",
        "    - If the query requires graph-based computations, extract the **NetworkX algorithm** (e.g., PageRank, Shortest Path, Community Detection,betweenness).\n",
        "    - Ensure **strict JSON output** with **no explanations**.\n",
        "\n",
        "    ### **Example Format:**\n",
        "    {{\n",
        "      \"AQL\": \"WITH medical_node, medical_node_to_medical_node\n",
        "              FOR patient IN medical_node\n",
        "                  FILTER patient.type == 'Patient'\n",
        "                  FOR diagnosis IN medical_node_to_medical_node\n",
        "                      FILTER diagnosis._from == patient._id AND diagnosis.type == 'PATIENT_DIAGNOSED_WITH'\n",
        "                      FOR disease IN medical_node\n",
        "                          FILTER disease._id == diagnosis._to AND disease.id == 'Diabetes'\n",
        "                          FOR symptomEdge IN medical_node_to_medical_node\n",
        "                              FILTER symptomEdge._from == patient._id AND symptomEdge.type == 'PATIENT_HAS_SYMPTOM'\n",
        "                              FOR symptom IN medical_node\n",
        "                                  FILTER symptom._id == symptomEdge._to\n",
        "                                  RETURN symptom\",\n",
        "      \"Algorithm\": \"\"\n",
        "    }}\n",
        "\n",
        "    ### **Query:** \"{query}\"\n",
        "\n",
        "    ### **Your response must contain only JSON:**\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt).content\n",
        "\n",
        "    # Strip any markdown code block formatting if present\n",
        "    response = response.strip(\"```json\").strip(\"```\").strip()\n",
        "\n",
        "    try:\n",
        "        execution_plan = json.loads(response)  # SAFER than eval()\n",
        "    except json.JSONDecodeError:\n",
        "        logging.error(\"Failed to parse LLM response. Raw response: %s\", response)\n",
        "        print(\"error: Invalid response from LLM.\")\n",
        "\n",
        "    aql_query = execution_plan.get(\"AQL\", \"\").strip()\n",
        "    nx_query = execution_plan.get(\"Algorithm\", \"\").strip()\n",
        "    # print(aql_query)\n",
        "\n",
        "    # Ensure single quotes are retained\n",
        "    aql_query = aql_query.replace('\"', \"'\")\n",
        "\n",
        "    # print(\"AQL Query:\", aql_query)\n",
        "    # print(\"NetworkX Algorithm:\", nx_query)\n",
        "    print(\"n1)Generating and Executing AQL query\")\n",
        "    # Step 2: AQL Execution\n",
        "    edge_types = [\n",
        "        \"DISEASE_HAS_TREATMENT\",\n",
        "        \"PATIENT_DIAGNOSED_WITH\",\n",
        "        \"DISEASE_HAS_DRUG\",\n",
        "        \"SYMPTOM_INDICATES_DISEASE\",\n",
        "        \"DISEASE_HAS_GENE\",\n",
        "        \"DRUG_INTERACTS_WITH\",\n",
        "        \"PATIENT_HAS_SYMPTOM\"\n",
        "    ]\n",
        "\n",
        "    if aql_query:\n",
        "        instruction_prompt = (\n",
        "            f\"You are an expert in graph databases and AQL. Your task is to analyze the given \"\n",
        "            f\"natural language query and determine whether an edge type from the following list \"\n",
        "            f\"is required: {', '.join(edge_types)}.\\n\\n\"\n",
        "            \"If an edge type is required, **strictly select one** from this list and use it in the AQL query.\\n\"\n",
        "            \"**Do NOT create or assume any other edge types beyond this list.**\\n\\n\"\n",
        "            \"If no edge type is required, generate a standard AQL query without using any edge.\\n\\n\"\n",
        "            f\"Here is the user query:\\n\\n{aql_query}\"\n",
        "        )\n",
        "\n",
        "        chain = ArangoGraphQAChain.from_llm(\n",
        "            llm=llm,\n",
        "            graph=arango_graph,\n",
        "            verbose=True,\n",
        "            allow_dangerous_requests=True\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            aql_result = chain.invoke(instruction_prompt)[\"result\"]\n",
        "        except Exception as e:\n",
        "            logging.error(\"AQL Execution Failed: %s\", str(e))\n",
        "            aql_result = \"AQL Execution Failed\"\n",
        "    else:\n",
        "        aql_result = None\n",
        "\n",
        "    # print(aql_result)\n",
        "\n",
        "    logging.info(\"Generated AQL Query: %s\", aql_result)\n",
        "\n",
        "    ###Extracting the nodes from AQL result\n",
        "\n",
        "    # Define the system prompt\n",
        "    system_prompt = \"\"\"You will be given an original query and a raw_result containing an AQL result.\n",
        "    Assess both and extract **only the relevant entities** dynamically.\n",
        "\n",
        "    ### **Rules:**\n",
        "    1. Identify **categories** (e.g., Symptoms, Drugs, Treatments, Patients) mentioned in both the query and raw_result.\n",
        "    2. Extract **all items** under those categories.\n",
        "    3. Return only a **flat list** of extracted entities (no categories, no explanations).\n",
        "\n",
        "    ### **Example Output Format:**\n",
        "    [\"Blurred Vision\", \"Fatigue\", \"Frequent Urination\", \"Metformin\", \"Insulin\", \"Exercise\"]\"\"\"\n",
        "\n",
        "    # Invoke the LLM\n",
        "    response = llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Query: {query}\\nRaw Result: {aql_result}\"}\n",
        "    ])\n",
        "\n",
        "    # Extract response and parse as a list\n",
        "    extracted_entities = json.loads(response.content)\n",
        "\n",
        "    # Print or use extracted_entities\n",
        "    print(extracted_entities)\n",
        "\n",
        "\n",
        "\n",
        "    # Step 3: NetworkX Execution (Over the whole graph)\n",
        "    print('-' * 10)\n",
        "    print(\"\\n2)Generating NetworkX code\")\n",
        "\n",
        "    NX_ALGORITHM_TEMPLATES = {\n",
        "    \"PageRank\": \"nx.pagerank(G_adb)\",\n",
        "    \"Betweenness Centrality\": \"nx.betweenness_centrality(G_adb)\",\n",
        "    \"Community Detection\": \"nx.algorithms.community.greedy_modularity_communities(G_adb)\",\n",
        "    }\n",
        "\n",
        "    # nx_query = \"PageRank\"\n",
        "    text_to_nx = llm.invoke(f'''\n",
        "    Given the following NetworkX query:\n",
        "    {nx_query}\n",
        "    Generate Python code to execute it on a NetworkX graph `G_adb`\n",
        "    and store the result in a variable named `nx_result`.\n",
        "    Use the predefined templates{NX_ALGORITHM_TEMPLATES} for common NetworkX algorithms depending on the query before generating new ones.\n",
        "    **Your response should contain ONLY Python code.**\n",
        "            ''').content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^\\`\\`\\`python\\n|\\`\\`\\`$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "    print(text_to_nx_cleaned)\n",
        "    local_vars = {}\n",
        "    global_vars = {\"G_adb\": G_adb}  # Assuming G_adb is the graph object\n",
        "    exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "    # nx.set_node_attributes(G_adb, pagerank_scores, \"pagerank\")\n",
        "    nx_result = local_vars[\"nx_result\"]\n",
        "    print(nx_result)\n",
        "    print(\"-------\")\n",
        "\n",
        "    print(aql_result)\n",
        "\n",
        "    #Step 4: Filtering out the required nodes and formulating the final answer\n",
        "    # print(aql_results)\n",
        "    symptom_ids = extracted_entities\n",
        "    print(symptom_ids)\n",
        "\n",
        "    # Extract PageRank results for the symptoms in aql_results\n",
        "    symptom_metric = {node_data['id']: nx_result[node]\n",
        "                        for node, node_data in G_adb.nodes(data=True)\n",
        "                        if node_data.get('id') in symptom_ids}\n",
        "    print(symptom_metric)\n",
        "\n",
        "    # Extract symptom IDs from aql_results\n",
        "\n",
        "    # Find the symptom with the highest PageRank\n",
        "    # max_symptom, (max_symptom_id, max_pagerank) = max(symptom_pagerank.items(), key=lambda x: x[1][1])\n",
        "    max_symptom, max_metric = max(symptom_metric.items(), key=lambda x: x[1])\n",
        "    # print(\"done2\")\n",
        "    final_result = {\"id\": max_symptom, \"metric\": max_metric}\n",
        "\n",
        "\n",
        "    # print(\"Filtered Symptom PageRank:\", symptom_pagerank)\n",
        "    # print(\"Final max PageRank:\", final_result)\n",
        "\n",
        "    print(\"n3) Formulating final answer\")\n",
        "\n",
        "    # Step 4: Generate Final Combined Response\n",
        "    final_response = llm.invoke(f'''\n",
        "    You are a data scientist responsible for inferencing from the final result.\n",
        "\n",
        "    Given the final result{final_result} and the metric name {nx_query}\n",
        "    Mention which has the highest metric value and what does it represent\n",
        "    Format a clear and insightful compact response summarizing the findings. Ensure it is understandable to non-technical users.\n",
        "    Also you can take help of the 'id' in {aql_result} to just name the options that were available.\n",
        "    ''').content\n",
        "# print(final_response)\n",
        "\n",
        "    return {\n",
        "        \"Final Response\": final_response\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "s4My-rbbC1w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Subgraph"
      ],
      "metadata": {
        "id": "bfVrwe6kRH8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import networkx as nx\n",
        "\n",
        "@tool\n",
        "def extract_nx_subgraph(query):\n",
        "    \"\"\"\n",
        "    Extracts a subgraph from a NetworkX graph (converted from ArangoDB) based on an LLM-generated query.\n",
        "\n",
        "    Parameters:\n",
        "        G_adb (ArangoDB graph): The source graph from ArangoDB.\n",
        "        nx_query (str): The natural language query specifying subgraph extraction criteria.\n",
        "        llm: The language model used to generate extraction code.\n",
        "\n",
        "    Returns:\n",
        "        networkx.Graph: The extracted subgraph.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "    # Initialize a NetworkX graph\n",
        "    G_nx = nx.Graph()\n",
        "\n",
        "    # Convert ArangoDB nodes to NetworkX\n",
        "    for node_key, attributes in G_adb.nodes(data=True):\n",
        "        G_nx.add_node(node_key, **attributes)\n",
        "\n",
        "    # Convert ArangoDB edges to NetworkX\n",
        "    for u, v, attributes in G_adb.edges(data=True):\n",
        "        G_nx.add_edge(u, v, **attributes)\n",
        "\n",
        "    # Generate NetworkX extraction code from LLM\n",
        "    valid_node_types = {'Treatment', 'Unknown', 'Symptom', 'Gene', 'Drug', 'Patient', 'Disease'}\n",
        "\n",
        "    text_to_nx = llm.invoke(f'''\n",
        "        You are an AI assistant that generates simple, executable Python code for extracting subgraphs in NetworkX.\n",
        "        The user provides a query {query} specifying which nodes and edges to extract, and you return Python code (not in a function) that does the extraction.\n",
        "\n",
        "        - The input graph is `G_nx` (do not redefine it).\n",
        "        - The graph contains **only** these node types: {valid_node_types}.\n",
        "        - Dont use any edge to create the subgraph just use G_nx.subgraph(nodes_to_extract).copy()\n",
        "        - **Ensure that extracted node types match the exact case and spelling as provided.**\n",
        "        - The code should dynamically determine which nodes and edges to extract based on the query.\n",
        "        - Use `subgraph = ...` to store the extracted graph.\n",
        "        - Do not include explanations, comments, or function definitions.\n",
        "        - The code should be executable via `exec()`.\n",
        "    ''').content\n",
        "\n",
        "    # Clean LLM output (remove code block markers if present)\n",
        "    text_to_nx_cleaned = re.sub(r\"^\\`\\`\\`python\\n|\\`\\`\\`$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print(text_to_nx_cleaned)\n",
        "    print(\"-----------\")\n",
        "\n",
        "    # Extract node_types_to_extract if present\n",
        "    match = re.search(r\"node_types_to_extract\\s*=\\s*(\\{.*?\\})\", text_to_nx_cleaned, re.DOTALL)\n",
        "    extracted_var = eval(match.group(1)) if match else set()\n",
        "\n",
        "    # Execute the generated code\n",
        "    local_vars = {}\n",
        "    global_vars = {\"G_nx\": G_nx, \"node_types_to_extract\": extracted_var}\n",
        "    exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "\n",
        "    subgraph = local_vars.get(\"subgraph\", None)\n",
        "    if subgraph is None:\n",
        "        print(\"No subgraph extracted.\")\n",
        "        return None\n",
        "\n",
        "    # Get a sample node (if available)\n",
        "    sample_node = next(iter(subgraph.nodes(data=True)), (\"No nodes in subgraph\", {}))\n",
        "\n",
        "    # Get a sample edge (if available)\n",
        "    sample_edge = next(iter(subgraph.edges(data=True)), (\"No edges in subgraph\", {}, {}))\n",
        "\n",
        "    # Print the summary\n",
        "    print(f\"\"\"\n",
        "    The extracted subgraph includes nodes and edges related to the subgraph.\n",
        "\n",
        "    - **Nodes**: {subgraph.number_of_nodes()}\n",
        "    - **Edges**: {subgraph.number_of_edges()}\n",
        "\n",
        "    ### Sample Node\n",
        "    - **ID**: {sample_node[0]}\n",
        "    - **Details**: {sample_node[1]}\n",
        "\n",
        "    ### Sample Edge\n",
        "    - **From Node**: {sample_edge[0]}\n",
        "    - **To Node**: {sample_edge[1]}\n",
        "    - **Details**: {sample_edge[2]}\n",
        "    \"\"\")\n",
        "\n",
        "    return subgraph\n",
        "\n"
      ],
      "metadata": {
        "id": "euEvYBryvhTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Visualisation Over A Subgraph"
      ],
      "metadata": {
        "id": "fFTxeTNsRQPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import json\n",
        "import matplotlib.patches as mpatches\n",
        "@tool\n",
        "def visualize_metrics(query):\n",
        "    \"\"\"\n",
        "    Extracts a subgraph, applies the required NetworkX algorithm(s),\n",
        "    and visualizes the results.\n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"subgraph_query\": str,\n",
        "            \"algorithms\": list,\n",
        "            \"subgraph_summary\": dict,\n",
        "            \"metrics\": dict\n",
        "        }\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")  # Initialize the LLM\n",
        "\n",
        "    # First LLM: Determine if a subgraph is needed & extract the algorithm\n",
        "    extraction_prompt = f'''\n",
        "        You are an AI assistant that determines which NetworkX algorithm should be applied\n",
        "        to a graph based on the user query: \"{query}\".\n",
        "        If a subgraph needs to be created, generate a natural language query for extracting it.\n",
        "\n",
        "        Return the output in JSON format with the keys:\n",
        "        \"subgraph_query\": \"query to extract relevant nodes and edges\",\n",
        "        \"algorithms\": [\"algorithm_1\", \"algorithm_2\", ...].\n",
        "    '''\n",
        "\n",
        "    extraction_response = llm.invoke(extraction_prompt).content\n",
        "    extraction_response_cleaned = re.sub(r\"```json\\n|```\", \"\", extraction_response, flags=re.MULTILINE).strip()\n",
        "    extraction_data = json.loads(extraction_response_cleaned)  # Convert JSON string to dictionary\n",
        "\n",
        "    subgraph_query = extraction_data[\"subgraph_query\"]\n",
        "    algorithms = extraction_data[\"algorithms\"]\n",
        "\n",
        "    # Extract the subgraph\n",
        "    subgraph = extract_nx_subgraph(subgraph_query)\n",
        "\n",
        "    if subgraph.number_of_nodes() == 0:\n",
        "        return {\n",
        "            \"subgraph_query\": subgraph_query,\n",
        "            \"algorithms\": algorithms,\n",
        "            \"subgraph_summary\": {\"nodes\": 0, \"edges\": 0},\n",
        "            \"metrics\": None,\n",
        "            \"message\": \"No nodes found in the subgraph.\"\n",
        "        }\n",
        "\n",
        "    # Second LLM: Generate code to apply NetworkX algorithms\n",
        "    algo_prompt = f'''\n",
        "    You are an AI assistant that generates Python code to apply\n",
        "    NetworkX algorithms on a given subgraph. The user wants to apply: {algorithms}.\n",
        "\n",
        "    - The input graph is `subgraph` (do not redefine it).\n",
        "    - Store the computed values as attributes in `subgraph`.\n",
        "    - Use the variable names based on the algorithm (e.g., `pagerank_scores`, `betweenness_scores`).\n",
        "    - Do not include explanations, comments, or function definitions.\n",
        "    - The code should be executable via `exec()`.\n",
        "    '''\n",
        "\n",
        "    algo_code = llm.invoke(algo_prompt).content\n",
        "    algo_code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", algo_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # Execute the generated code\n",
        "    exec(algo_code_cleaned, {\"subgraph\": subgraph})\n",
        "\n",
        "    # Collect computed metric values\n",
        "    metrics = {}\n",
        "    for algo in algorithms:\n",
        "        metrics[algo] = {n: subgraph.nodes[n].get(algo, None) for n in subgraph.nodes}\n",
        "\n",
        "    # Visualization setup\n",
        "    pos = nx.spring_layout(subgraph, seed=42)\n",
        "\n",
        "    def plot_graph(metric_name, node_colors, metric_values):\n",
        "        plt.figure(figsize=(14, 10))  # Increase figure size\n",
        "\n",
        "        # Normalize node colors based on metric values\n",
        "        cmap = plt.cm.Paired\n",
        "        norm = plt.Normalize(vmin=min(metric_values), vmax=max(metric_values))\n",
        "        node_colors = [cmap(norm(val)) for val in metric_values]\n",
        "\n",
        "        # Draw graph without labels to prevent overlap\n",
        "        nx.draw(subgraph, pos, with_labels=True, node_color=node_colors, cmap=cmap,\n",
        "                edge_color=\"black\", node_size=600, alpha=0.9, font_size=10, font_weight=\"bold\")\n",
        "\n",
        "        # **Fix: Dynamically determine unique colors for the legend**\n",
        "        unique_values = sorted(set(metric_values))  # Get distinct metric values\n",
        "        num_categories = 3  # Define number of legend categories (High, Medium, Low)\n",
        "        category_labels = [\"Low Centrality\", \"Medium Centrality\", \"High Centrality\"]\n",
        "\n",
        "        # Map distinct values into 3 categories evenly\n",
        "        split_indices = np.linspace(0, len(unique_values) - 1, num_categories, dtype=int)\n",
        "        category_values = [unique_values[i] for i in split_indices]\n",
        "\n",
        "        # Ensure correct color mapping for legend\n",
        "        legend_patches = [\n",
        "            mpatches.Patch(color=cmap(norm(val)), label=label) for val, label in zip(category_values, category_labels)\n",
        "        ]\n",
        "\n",
        "        # Adjust legend position\n",
        "        plt.legend(handles=legend_patches, loc=\"upper left\", fontsize=12, frameon=True, shadow=True)\n",
        "\n",
        "        # Title\n",
        "        plt.title(f\"{metric_name} (Subgraph)\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Generate plots for all algorithms\n",
        "    for algo in algorithms:\n",
        "        # Ensure all nodes have a valid metric value (default to 0 if missing)\n",
        "        metric_values = [subgraph.nodes[n].get(algo, 0) or 0 for n in subgraph.nodes]\n",
        "\n",
        "        # Handle case where all values are zero (to avoid normalization error)\n",
        "        if max(metric_values) == min(metric_values):  # All values are the same\n",
        "            print(f\"Skipping visualization for {algo} as all values are zero.\")\n",
        "            continue\n",
        "\n",
        "        # Normalize colors based on metric values\n",
        "        cmap = plt.cm.Paired\n",
        "        norm = plt.Normalize(vmin=min(metric_values), vmax=max(metric_values))  # Safe normalization\n",
        "        node_colors = [cmap(norm(val)) for val in metric_values]\n",
        "\n",
        "        # Ensure we only plot if there are meaningful values\n",
        "        plot_graph(algo.replace(\"_\", \" \").title(), node_colors, metric_values)\n",
        "\n",
        "    return {\n",
        "        \"subgraph_query\": subgraph_query,\n",
        "        \"algorithms\": algorithms,\n",
        "        \"metrics\": metrics,\n",
        "        \"message\": \"Visualization completed.\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "7H9iwDoTRqtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating The Agent Using Autogen**"
      ],
      "metadata": {
        "id": "YoB8NZSCRi1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "\n",
        "# âœ… Define the tools\n",
        "tools = {\n",
        "    \"text_to_aql_to_text\": text_to_aql_to_text,\n",
        "    \"text_to_nx_algorithm_to_text\": text_to_nx_algorithm_to_text,\n",
        "    \"execute_hybrid_query\": execute_hybrid_query,\n",
        "    \"extract_nx_subgraph\": extract_nx_subgraph,\n",
        "    \"visualize_metrics\": visualize_metrics\n",
        "}\n",
        "\n",
        "# âœ… System prompt (same as LangGraph)\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI assistant that selects the best tool to analyze a graph query.\n",
        "Use the following rules:\n",
        "- If the query **only requires retrieving or filtering nodes/edges from ArangoDB**, use `text_to_aql_to_text`.\n",
        "  - Example: \"Find all patients diagnosed with Diabetes.\"\n",
        "  - Example: \"List all diseases connected to Hypertension.\"\n",
        "\n",
        "- If the query **requires complex graph algorithms (PageRank, community detection, shortest path, etc.)**, use `text_to_nx_algorithm_to_text`.\n",
        "  - Example: \"Find the most influential disease using PageRank.\"\n",
        "  - Example: \"Detect communities of interconnected patients.\"\n",
        "\n",
        "- If the query **needs both AQL (to filter data) and NetworkX (to process it)**, use `execute_hybrid_query`.\n",
        "  - Example: \"Identify the most influential symptom among patients with Diabetes using PageRank.\"\n",
        "  - Example: \"Find the drugs available and compute its betweenness Centrality.\"\n",
        "\n",
        "- If the query **requires extracting a subgraph from NetworkX**, use `extract_nx_subgraph`.\n",
        "  - Example: \"Extract a subgraph of diseases, symptoms, and treatments.\"\n",
        "\n",
        "- If the query **requires both extracting a subgraph and visualizing NetworkX metrics**, use `visualize_metrics`.\n",
        "  - Example: \"Visualize the Betweenness Centrality values for a subgraph of diseases, symptoms, and treatments.\"\n",
        "  - Example: \"Show the PageRank values for a subgraph of interconnected medical conditions.\"\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Create the agent with the system prompt\n",
        "graph_agent = autogen.AssistantAgent(\n",
        "    name=\"GraphAssistant\",\n",
        "    llm_config={\"model\": \"gpt-4o\"},\n",
        "    system_message=SYSTEM_PROMPT\n",
        ")\n",
        "\n",
        "# âœ… Function to process the query using Autogen\n",
        "def query_graph_with_autogen(query):\n",
        "    try:\n",
        "        # ðŸ”¹ Ensure Autogen returns a structured response\n",
        "        response = graph_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": query}], return_messages=True)\n",
        "\n",
        "        # ðŸ”¹ Debug: Print the raw response from Autogen\n",
        "        print(\"\\nðŸ” RAW RESPONSE FROM AUTOGEN:\", response)\n",
        "\n",
        "        # ðŸ”¹ Extract last message\n",
        "        if isinstance(response, list) and len(response) > 0:\n",
        "            last_message = response[-1]  # Get last message if response is a list\n",
        "        else:\n",
        "            last_message = response  # Assume response is a single message\n",
        "\n",
        "        # ðŸ”¹ Extract tool name using regex\n",
        "        if isinstance(last_message, dict) and \"content\" in last_message:\n",
        "            raw_tool_name = last_message[\"content\"].strip()\n",
        "        elif isinstance(last_message, str):\n",
        "            raw_tool_name = last_message.strip()\n",
        "        else:\n",
        "            return \"Error: Unexpected response format from Autogen.\"\n",
        "\n",
        "        # âœ… Extract the valid tool name using regex\n",
        "        match = re.search(r\"\\b(text_to_aql_to_text|text_to_nx_algorithm_to_text|execute_hybrid_query|extract_nx_subgraph|visualize_metrics)\\b\", raw_tool_name)\n",
        "        if match:\n",
        "            tool_name = match.group(0)  # Extract the first valid tool name\n",
        "        else:\n",
        "            return f\"Error: Unable to extract a valid tool name from Autogen response - `{raw_tool_name}`\"\n",
        "\n",
        "        # ðŸ”¹ Validate if the selected tool exists\n",
        "        if tool_name in tools:\n",
        "            print(f\"\\nâœ… Selected Tool: {tool_name}\")\n",
        "            return tools[tool_name](query)  # Execute the selected tool\n",
        "        else:\n",
        "            return f\"Error: Unknown tool selected by the agent - `{tool_name}`\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error processing query: {e}\""
      ],
      "metadata": {
        "id": "2-M5mM5rfyiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Query Testing**"
      ],
      "metadata": {
        "id": "DJa-Jwb_R_Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Who is the most popular node in the Graph?Explain why\")"
      ],
      "metadata": {
        "id": "7ATpzUbhR5tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_graph_with_autogen(\"How strongly connected is the network? Used connected components.\"))"
      ],
      "metadata": {
        "id": "VQjS7ksQH6mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Translate this natural language query into AQL: 'Find all diseases treated by drug Aspirin'\")"
      ],
      "metadata": {
        "id": "swpCt1kGR-pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_graph_with_autogen(\"Check how drug type Ibuprofen interacts with other drugs.Use aql\"))"
      ],
      "metadata": {
        "id": "NFTjtzjKsEAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_graph_with_autogen(\"List recommended treatments for the disease Hypertension\"))"
      ],
      "metadata": {
        "id": "yomXH1tBwHfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Identify the most influential symptom among patients diagnosed with Diabetes using PageRank analysis.\")"
      ],
      "metadata": {
        "id": "hWiwX_nT2iCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Find the drugs available and compute its betweenness Centrality.\")"
      ],
      "metadata": {
        "id": "y59GcOBnTWug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Identify the most influential drugs for disease id Asthma using PageRank analysis.\")"
      ],
      "metadata": {
        "id": "T0mCIz30Tpe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Extract a subgraph of drugs, Disease, symptoms, and Treatments.\")"
      ],
      "metadata": {
        "id": "P3nbBcY6TaIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Visualize only the Betweenness values for a subgraph of diseases and treatments.\")"
      ],
      "metadata": {
        "id": "xafYCl2iTwIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_graph_with_autogen(\"Visualize only the Pagerank values for a subgraph of Diseases and Symptoms.\")"
      ],
      "metadata": {
        "id": "6EvPQC_jT3ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(fn=query_graph, inputs=\"text\", outputs=\"text\").launch(share=True)"
      ],
      "metadata": {
        "id": "NAho5SEf2nCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}